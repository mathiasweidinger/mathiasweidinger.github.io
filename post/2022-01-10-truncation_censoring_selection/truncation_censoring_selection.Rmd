---
aliases:
- "truncation_censoring_selection"

date: "2022-01-10"
title: "Understanding limited data"
subtitle: "truncation, censoring, and selection"
author: "Mathias Weidinger"

categories: []
tags: ["truncation", "censored", "selection", "limited data", "R", "econometrics"]

cover:
    #image: ""
    alt: ""
    caption: ""
    relative: false
    
hidemeta: false
showtoc: false
showBreadCrumbs: false

draft: true
math: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

For this demonstration in R, we need to load the following packages...

```{r, include = TRUE, echo = TRUE , warning = FALSE, message = FALSE}

# load packages
library(AER)        # example datasets
library(tidyverse)  # the almighty tidyverse
library(magrittr)   # double pipe operator
library(ggpubr)     # combine multiple graphs
```

# What is a limited dataset?

In econometrics,we often rely on the assumption that our data is distributed in way that is clearly defined, mathematically "well-behaved" and, therefore, easy to work with. We call some models *parametric* because they work by adjusting one or more parameters of a well-known function in such a way that it fits the data well. Let 's see what that looks like in practice.

Take, for instance, the normal (aka "Gaussian") distribution, which is commonly used to model continuous data. If you have ever set through an introductory statistics course, you will remember that the normal distribution is a type of probability distribution for a real-valued random variable. The general form of its probability density function (PDF) is

$$
f(x)=\frac{1}{\sigma \sqrt{2 \pi}}e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}
$$
This function has two parameters, $\mu$ and $\sigma$. $\mu$ is the mean or expectation of the distribution (and also its median and mode), while $\sigma$ is its standard deviation. And yes, that means that the variance of the distribution is $\sigma^2$. A random variable with a Gaussian distribution is said to be normally distributed, and many real world phenomena happen to be (approximately) normally distributed. To see why that might be, let's visualize what the normal distribution's PDF looks like.

```{r echo = T, eval = FALSE}
(
p9 <- ggplot(data.frame(x = c(-4, 4)), aes(x = x)) +
    stat_function(fun = dnorm) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "red")
)
```


```{r bellcurve, echo = FALSE, fig.cap='PDF of a standard normal distribution. Red dashed line indicates mean.'}
(
p9 <- ggplot(data.frame(x = c(-4, 4)), aes(x = x)) +
    stat_function(fun = dnorm) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "red")
)
```

Note that the normal distribution is inherently symmetric and centered above $\mu$. For the figure above, $x$ is normally distributed with mean zero and a variance of one; we call this a "standard-normal" distribution and it's written as $x\sim\mathcal{N}(\mu=0, \sigma^2=1)$. Roughly speaking, saying that some random variable is normally distributed means that it's PDF follows this characteristically symmetric bell-shape which peaks at the variable's mean. The probability that we observe a value left of the mean should be equal to the probability of observing a value right of it. The further a value is away from the mean, the more improbable is it that we observe it.

So why is the normal distribution so useful in modelling real world phenomena? Well, first off the bell-shape implies that a random draw from a population will, most likely, fall close to the mean of that population, and that it is very unlikely that we would draw an observation at the extreme ends of the population's distribution. Say we are measuring the height of twelve-year-olds. If we draw any random individual from that group, they are almost certainly between 1 meter and 1.70 meters tall. The probability of sampling someone smaller than 1 m is close to zero, as is the probability of sampling someone taller than 2m. This admittedly obvious example is to say that, in nature, many things are rather alike in many ways and the extremes are very rare (duh). So that is why the general shape of the normal distribution (few obs at the tails, many at the middle) is so attractive.

Its symmetry is what makes the normal distribution so easy to work with mathematically. However, this symmetry is not nearly as common in real world phenomena as the simple down-up-down pattern. Real life often presents us with data that does not readily fit a normal distribution due to a lack of symmetry. While this *may* happen as a result of faulty measurement (we call this "measurement error"), that does not have to be the case. In fact, even if the measurement is reasonably close to the truth (because no measurement is ever 100% spot on), we might have limited data due to the very nature of the phenomenon at hand.

Perhaps the most commonly noted examples (among economists) come from labor economics. Two key metrics in this area are hours of work and hourly wages, for both of which we only have limited measurements. Graphically, limited data usually more or less follows a normal distribution for some but not all its values. In econometrics, this is most relevant when the dependent variable in a regression is limited in one of three ways: it is either censored, truncated, or exhibits selection.

Let's consider these three distinct concepts using an example: the US 1976 Panel Study on Income Dynamics (PSID1976). Thomas A. Mroz used these data in his [1987 article in *Econometrica*](https://www.jstor.org/stable/1911029) to analyse the labour supply of married women. The data set ships with the R-package `AER` (Kleiber & Zeileis, [2020](https://cran.r-project.org/web/packages/AER/index.html)).

## Censoring vs truncation vs selection

Let's start with censoring. Say we observe a continuous variable. Choose some value and set all values below (or above) it equal to this threshold. What we get is a data set that has not lost any observations (the sample size is exactly the same) but some information because the variation below (above) the cut-off was eliminated.

This may happen as a result of survey methodology: Consider a survey that asks about respondents' income, but codes everyone earning more than 100,000 USD as "100,000 USD or more". As a result, the histogram of income will be approximately normal on the left but it will have a spike at 100,000 USD and no observations beyond this ceiling. This is an example of a "right-censored" variable.

Sometimes it is not methodology that's to blame. Consider the far more common case of observing all incomes in your sample. Unless we limit our sample to working individuals only, there will likely be a spike at zero, because of those individuals in our sample that do not work at all. This is called "left-censoring" because the otherwise normal density now has a spike left of the mean and nothing below it.

Let's turn to the  PSID1976 data. Panels A and B of Figure \@ref(fig:censored) plot yearly work hours and wage rates for 753 women in 1975. Panels C and D below show the respective probability densities. Clearly, neither of them look anything like the bell curve in Figure \@ref(fig:bellcurve).

----------

<details><summary>show source code</summary>
```{r, echo = TRUE, eval = FALSE}
# load data
data("PSID1976")

# plot histogram
hhist <- ggplot(data = PSID1976, aes(x = hours)) +
    geom_histogram(color = "black", fill = "white") +
    geom_vline(xintercept = mean(PSID1976$hours), linetype = "dashed", color = "red") +
    labs(title = "hours worked in 1975", caption = "(mean = 740.576)")

whist <- ggplot(data = PSID1976, aes(x = wage)) + 
    geom_histogram(color = "black", fill = "white", binwidth = 1) +
    geom_vline(xintercept = mean(PSID1976$wage), linetype = "dashed", color = "red") +
    labs(title = "hourly wage in 1975 USD", caption = "(mean = 2.375)")

hdens <- ggplot(data = PSID1976, aes(x = hours)) +
    geom_density() +
    labs(title = "density of hours worked")

wdens <- ggplot(data = PSID1976, aes(x = wage)) + 
    geom_density() +
    labs(title = "density of hourly wage")

figure <- ggarrange(hhist,whist,hdens,wdens, labels = c("A", "B", "C", "D"), ncol = 2, nrow = 2)
figure
```
</details>
```{r censored, include = TRUE, echo = FALSE, warning = FALSE, message = FALSE, fig.cap = 'Histograms and density plots for hours worked in 1975 and hourly wage rates. Red dashed lines indicate variable means.'}

# load data
data("PSID1976")

# plot histogram
hhist <- ggplot(data = PSID1976, aes(x = hours)) +
    geom_histogram(color = "black", fill = "white") +
    geom_vline(xintercept = mean(PSID1976$hours), linetype = "dashed", color = "red") +
    labs(title = "hours worked in 1975", caption = "(mean = 740.576)")

whist <- ggplot(data = PSID1976, aes(x = wage)) + 
    geom_histogram(color = "black", fill = "white", binwidth = 1) +
    geom_vline(xintercept = mean(PSID1976$wage), linetype = "dashed", color = "red") +
    labs(title = "hourly wage in 1975 USD", caption = "(mean = 2.375)")

hdens <- ggplot(data = PSID1976, aes(x = hours)) +
    geom_density() +
    labs(title = "density of hours worked")

wdens <- ggplot(data = PSID1976, aes(x = wage)) + 
    geom_density() +
    labs(title = "density of hourly wage")

figure <- ggarrange(hhist,whist,hdens,wdens, labels = c("A", "B", "C", "D"), ncol = 2, nrow = 2)
figure
```
----------

The data clearly shows that there are many women who do not work. For these people both their hours and wage rate are zero. But not all of them are the same. Some might abstain from working because they are too old, too young, in education or not able to work. Others may not want to work because there are not many jobs that fit their qualifications or priorities. Lastly, there may be people who actively look for a job but cannot find one and those who are between jobs (these are the long-term and temporary unemployed). This is an example of censoring because theory suggests that there is a theoretical la